{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa3fa567",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/57321948/196933065-4b16c235-f3b9-4391-9cfe-4affcec87c35.png)\n",
    "\n",
    "# Submitted by: Mohammad Wasiq\n",
    "\n",
    "## Email: `gl0427@myamu.ac.in`\n",
    "\n",
    "# Pre-Placement Training Assignment - `Big Data` \n",
    "\n",
    "## Data Warehousing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fef4477",
   "metadata": {},
   "source": [
    "## **TOPIC: Data Warehousing Fundamentals**\n",
    "\n",
    "**Q1. Design a data warehouse schema for a retail company that includes dimension tables for products, customers, and time. Implement the schema using a relational database management system (RDBMS) of your choice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5e06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Dimension Table\n",
    "\n",
    "CREATE TABLE product (\n",
    "  product_id INT PRIMARY KEY,\n",
    "  product_name VARCHAR(100),\n",
    "  category VARCHAR(50),\n",
    "  brand VARCHAR(50),\n",
    "  -- other product attributes\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b3db5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Dimension Table\n",
    "\n",
    "CREATE TABLE customer (\n",
    "  customer_id INT PRIMARY KEY,\n",
    "  customer_name VARCHAR(100),\n",
    "  city VARCHAR(50),\n",
    "  state VARCHAR(50),\n",
    "  -- other customer attributes\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08416c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Dimension Table\n",
    "\n",
    "CREATE TABLE time (\n",
    "  date_id DATE PRIMARY KEY,\n",
    "  day INT,\n",
    "  month INT,\n",
    "  year INT,\n",
    "  -- other time attributes\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8528ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales Fact Table\n",
    "\n",
    "CREATE TABLE sales (\n",
    "  sales_id INT PRIMARY KEY,\n",
    "  product_id INT,\n",
    "  customer_id INT,\n",
    "  date_id DATE,\n",
    "  quantity INT,\n",
    "  price DECIMAL(10, 2),\n",
    "  -- other sales metrics\n",
    "  FOREIGN KEY (product_id) REFERENCES product (product_id),\n",
    "  FOREIGN KEY (customer_id) REFERENCES customer (customer_id),\n",
    "  FOREIGN KEY (date_id) REFERENCES time (date_id)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f4040a",
   "metadata": {},
   "source": [
    "**Q2. Create a fact table that captures sales data, including product ID, customer ID, date, and sales amount. Populate the fact table with sample data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a38e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Sample Data into the Product Dimension Table:\n",
    "\n",
    "\n",
    "INSERT INTO product (product_id, product_name, category, brand)\n",
    "VALUES\n",
    "  (1, 'Product A', 'Category 1', 'Brand X'),\n",
    "  (2, 'Product B', 'Category 2', 'Brand Y'),\n",
    "  (3, 'Product C', 'Category 1', 'Brand Z');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebd58a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Sample Data into the Customer Dimension Table:\n",
    "\n",
    "\n",
    "INSERT INTO customer (customer_id, customer_name, city, state)\n",
    "VALUES\n",
    "  (1, 'Customer 1', 'City 1', 'State X'),\n",
    "  (2, 'Customer 2', 'City 2', 'State Y'),\n",
    "  (3, 'Customer 3', 'City 3', 'State Z');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b7af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Sample Data into the Time Dimension Table\n",
    "\n",
    "INSERT INTO time (date_id, day, month, year)\n",
    "VALUES\n",
    "  ('2023-01-01', 1, 1, 2023),\n",
    "  ('2023-01-02', 2, 1, 2023),\n",
    "  ('2023-01-03', 3, 1, 2023);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd9c5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Sample Data into the Sales Fact Table:\n",
    "\n",
    "\n",
    "INSERT INTO sales (sales_id, product_id, customer_id, date_id, quantity, price)\n",
    "VALUES\n",
    "  (1, 1, 1, '2023-01-01', 10, 100.00),\n",
    "  (2, 2, 2, '2023-01-02', 5, 50.00),\n",
    "  (3, 3, 3, '2023-01-03', 8, 80.00);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1a870c",
   "metadata": {},
   "source": [
    "**Q3. Write SQL queries to retrieve sales data from the data warehouse, including aggregations and filtering based on different dimensions.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81ee35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve total sales amount for each product:\n",
    "\n",
    "\n",
    "SELECT p.product_name, SUM(s.quantity * s.price) AS total_sales_amount\n",
    "FROM sales s\n",
    "JOIN product p ON s.product_id = p.product_id\n",
    "GROUP BY p.product_name;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c95d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve total sales amount for each customer:\n",
    "\n",
    "\n",
    "SELECT c.customer_name, SUM(s.quantity * s.price) AS total_sales_amount\n",
    "FROM sales s\n",
    "JOIN customer c ON s.customer_id = c.customer_id\n",
    "GROUP BY c.customer_name;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abf8d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve total sales amount for each month:\n",
    "\n",
    "\n",
    "SELECT t.month, SUM(s.quantity * s.price) AS total_sales_amount\n",
    "FROM sales s\n",
    "JOIN time t ON s.date_id = t.date_id\n",
    "GROUP BY t.month;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bff0aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve total sales amount for a specific product category:\n",
    "\n",
    "\n",
    "SELECT p.category, SUM(s.quantity * s.price) AS total_sales_amount\n",
    "FROM sales s\n",
    "JOIN product p ON s.product_id = p.product_id\n",
    "WHERE p.category = 'Category 1'\n",
    "GROUP BY p.category;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf25e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve total sales amount for a specific customer in a specific month:\n",
    "\n",
    "\n",
    "SELECT c.customer_name, t.month, SUM(s.quantity * s.price) AS total_sales_amount\n",
    "FROM sales s\n",
    "JOIN customer c ON s.customer_id = c.customer_id\n",
    "JOIN time t ON s.date_id = t.date_id\n",
    "WHERE c.customer_name = 'Customer 1' AND t.month = 1\n",
    "GROUP BY c.customer_name, t.month;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b3c429",
   "metadata": {},
   "source": [
    "## TOPIC: ETL and Data Integration\n",
    "\n",
    "**Q1. Design an ETL process using a programming language (e.g., Python) to extract data from a source system (e.g., CSV files), transform it by applying certain business rules or calculations, and load it into a data warehouse.**\n",
    "\n",
    "**Ans :** \n",
    "\n",
    "**Extraction:**\n",
    "* Read the CSV files using Python's CSV module or pandas library.\n",
    "* Extract the required columns and relevant data from the CSV files.\n",
    "\n",
    "**Transformation:**\n",
    "* Apply any necessary data transformations, such as cleaning the data, handling missing values, or converting data types.\n",
    "* Perform business rule calculations or any other required transformations on the extracted data.\n",
    "\n",
    "**Loading:**\n",
    "* Connect to the data warehouse using appropriate libraries or modules, such as SQLAlchemy for relational databases or PyMongo for MongoDB.\n",
    "* Create the necessary tables or collections in the data warehouse to store the transformed data.\n",
    "* Load the transformed data into the respective tables or collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c0fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Extraction\n",
    "data = []\n",
    "with open('data.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)  # Skip header\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "\n",
    "# Transformation\n",
    "df = pd.DataFrame(data, columns=['Column1', 'Column2', 'Column3'])\n",
    "# Apply transformations or calculations on the DataFrame\n",
    "\n",
    "# Loading\n",
    "engine = create_engine('database_connection_string')\n",
    "df.to_sql('table_name', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39242f8",
   "metadata": {},
   "source": [
    "**Q2. Implement the ETL process by writing code that performs the extraction, transformation, and loading steps.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc07f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Extraction\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Transformation\n",
    "# Apply any necessary transformations or calculations on the DataFrame\n",
    "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n",
    "\n",
    "# Loading\n",
    "engine = create_engine('database_connection_string')\n",
    "df.to_sql('sales', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45b8090",
   "metadata": {},
   "source": [
    "## TOPIC: Dimensional Modeling and Schemas\n",
    "\n",
    "**Q1. Design a star schema for a university database, including a fact table for student enrollments and dimension tables for students, courses, and time. Implement the schema using a database of your choice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df30b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Create Fact Table\n",
    "CREATE TABLE enrollments (\n",
    "    enrollment_id SERIAL PRIMARY KEY,\n",
    "    student_id INTEGER REFERENCES students (student_id),\n",
    "    course_id INTEGER REFERENCES courses (course_id),\n",
    "    time_id INTEGER REFERENCES time (time_id),\n",
    "    grade FLOAT\n",
    ");\n",
    "\n",
    "# -- Create Dimension Tables\n",
    "CREATE TABLE students (\n",
    "    student_id SERIAL PRIMARY KEY,\n",
    "    student_name VARCHAR(100),\n",
    "    student_major VARCHAR(50),\n",
    "    student_age INTEGER\n",
    ");\n",
    "\n",
    "CREATE TABLE courses (\n",
    "    course_id SERIAL PRIMARY KEY,\n",
    "    course_name VARCHAR(100),\n",
    "    course_department VARCHAR(50),\n",
    "    course_credits INTEGER\n",
    ");\n",
    "\n",
    "CREATE TABLE time (\n",
    "    time_id SERIAL PRIMARY KEY,\n",
    "    year INTEGER,\n",
    "    semester VARCHAR(50),\n",
    "    month INTEGER\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21b659f",
   "metadata": {},
   "source": [
    "**Q2. Write SQL queries to retrieve data from the star schema, including aggregations and joins between the fact table and dimension tables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2812bb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all enrollments with student and course details:\n",
    "\n",
    "\n",
    "SELECT e.enrollment_id, s.student_name, c.course_name, e.grade\n",
    "FROM enrollments e\n",
    "JOIN students s ON e.student_id = s.student_id\n",
    "JOIN courses c ON e.course_id = c.course_id;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7354bebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average grade for each student:\n",
    "\n",
    "\n",
    "SELECT s.student_name, AVG(e.grade) AS average_grade\n",
    "FROM enrollments e\n",
    "JOIN students s ON e.student_id = s.student_id\n",
    "GROUP BY s.student_name;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca22af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total number of enrollments by course department:\n",
    "\n",
    "\n",
    "SELECT c.course_department, COUNT(*) AS total_enrollments\n",
    "FROM enrollments e\n",
    "JOIN courses c ON e.course_id = c.course_id\n",
    "GROUP BY c.course_department;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef05dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the highest and lowest grades for a specific course:\n",
    "\n",
    "\n",
    "SELECT c.course_name, MAX(e.grade) AS highest_grade, MIN(e.grade) AS lowest_grade\n",
    "FROM enrollments e\n",
    "JOIN courses c ON e.course_id = c.course_id\n",
    "WHERE c.course_name = 'Course A';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f53e251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve enrollments for a specific semester and year:\n",
    "\n",
    "    \n",
    "SELECT e.enrollment_id, s.student_name, c.course_name, e.grade\n",
    "FROM enrollments e\n",
    "JOIN students s ON e.student_id = s.student_id\n",
    "JOIN courses c ON e.course_id = c.course_id\n",
    "JOIN time t ON e.time_id = t.time_id\n",
    "WHERE t.semester = 'Spring' AND t.year = 2022;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026fbb41",
   "metadata": {},
   "source": [
    "## TOPIC: Performance Optimization and Querying\n",
    "\n",
    "**Q1. Scenario: You need to improve the performance of your data loading process in the data warehouse. Write a Python script that implements the following optimizations:**\n",
    "\n",
    "**a)\tUtilize batch processing techniques to load data in bulk instead of individual row insertion.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8387f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "def load_data_in_batches(data, batch_size):\n",
    "    conn = psycopg2.connect(database=\"your_database\", user=\"your_user\", password=\"your_password\", host=\"your_host\", port=\"your_port\")\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Split the data into batches\n",
    "    num_batches = len(data) // batch_size + 1\n",
    "    for i in range(num_batches):\n",
    "        batch_data = data[i * batch_size: (i + 1) * batch_size]\n",
    "\n",
    "        # Generate a multi-row insert statement\n",
    "        insert_statement = \"INSERT INTO your_table (column1, column2, ...) VALUES \"\n",
    "        values = []\n",
    "        for row in batch_data:\n",
    "            values.append(f\"({row['column1_value']}, '{row['column2_value']}', ...)\")\n",
    "        insert_statement += \", \".join(values)\n",
    "\n",
    "        # Execute the insert statement\n",
    "        cursor.execute(insert_statement)\n",
    "    \n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "# Example usage\n",
    "data = [\n",
    "    {\"column1\": \"value1\", \"column2\": \"value2\", ...},\n",
    "    {\"column1\": \"value3\", \"column2\": \"value4\", ...},\n",
    "    ...\n",
    "]\n",
    "batch_size = 1000\n",
    "\n",
    "load_data_in_batches(data, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfd1142",
   "metadata": {},
   "source": [
    "**b)  Implement multi-threading or multiprocessing to parallelize the data loading process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db72134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Define the number of worker processes\n",
    "num_workers = 4\n",
    "\n",
    "def load_data(row):\n",
    "    # Connect to the database\n",
    "    conn = psycopg2.connect(database=\"your_database\", user=\"your_user\", password=\"your_password\", host=\"your_host\", port=\"your_port\")\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Perform the data insertion for a single row\n",
    "    insert_statement = f\"INSERT INTO your_table (column1, column2, ...) VALUES ({row['column1_value']}, '{row['column2_value']}', ...)\"\n",
    "    cursor.execute(insert_statement)\n",
    "\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "def load_data_parallel(data):\n",
    "    # Create a pool of worker processes\n",
    "    pool = Pool(num_workers)\n",
    "\n",
    "    # Load data in parallel using multiple processes\n",
    "    pool.map(load_data, data)\n",
    "\n",
    "    # Close the pool\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "# Example usage\n",
    "data = [\n",
    "    {\"column1\": \"value1\", \"column2\": \"value2\", ...},\n",
    "    {\"column1\": \"value3\", \"column2\": \"value4\", ...},\n",
    "    ...\n",
    "]\n",
    "\n",
    "load_data_parallel(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509e050b",
   "metadata": {},
   "source": [
    "**c)  Measure the time taken to load a specific amount of data before and after implementing these optimizations.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881d34a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import time\n",
    "\n",
    "# Original data loading function without optimizations\n",
    "def load_data_original(data):\n",
    "    conn = psycopg2.connect(database=\"your_database\", user=\"your_user\", password=\"your_password\", host=\"your_host\", port=\"your_port\")\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for row in data:\n",
    "        insert_statement = f\"INSERT INTO your_table (column1, column2, ...) VALUES ({row['column1_value']}, '{row['column2_value']}', ...)\"\n",
    "        cursor.execute(insert_statement)\n",
    "\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    print(f\"Original execution time: {execution_time} seconds\")\n",
    "\n",
    "# Optimized data loading function using multiprocessing\n",
    "def load_data_parallel(data):\n",
    "    conn = psycopg2.connect(database=\"your_database\", user=\"your_user\", password=\"your_password\", host=\"your_host\", port=\"your_port\")\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ... rest of the code ...\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    print(f\"Optimized execution time: {execution_time} seconds\")\n",
    "\n",
    "# Example usage\n",
    "data = [\n",
    "    {\"column1\": \"value1\", \"column2\": \"value2\", ...},\n",
    "    {\"column1\": \"value3\", \"column2\": \"value4\", ...},\n",
    "    ...\n",
    "]\n",
    "\n",
    "load_data_original(data)\n",
    "load_data_parallel(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
